"""
This module implements a Retrieval-Augmented Generation (RAG) pipeline for managing and querying concert-related documents
using ChromaDB and the Ollama language model. It provides functionalities to add documents to a collection, classify user
intent, and determine if a document is concert-related.

Key Functions:
- add_docs_to_collection(documents, ids): Adds specified documents to the ChromaDB collection with associated IDs.
- query_chromadb(query_text, n_results=1): Queries the ChromaDB collection for documents related to the provided query text.
- query_ollama(prompt, llm_model): Invokes the Ollama language model with a given prompt and returns the generated response.
- rag_pipeline(query_text): Executes the RAG pipeline by retrieving relevant documents and generating an answer using the Ollama model.
- classify_user_intent(user_input): Analyzes user input to determine if it is an intent to add a document or ask a question.
- is_concert_related(document_text): Checks if the provided text is related to concerts, tours, or performers.

Main Execution:
When run as a script, this module initializes a ChromaDB client, creates or retrieves a document collection, and populates it
with predefined concert-related documents. It then enters a loop to accept user queries, classify intents, and respond
accordingly, allowing users to add new documents or ask questions about existing ones.

Dependencies:
- os: For file path operations.
- chromadb: For managing the document collection.
- rag: For embedding functions.
- langchain_ollama: For interacting with the Ollama language model.

Usage:
1. Start the script to initialize the database and load starting documents.
2. Enter user queries to either add documents or ask questions.
3. Use 'exit' to terminate the program.

Example:
To add a document, input: "ADD: Lady Gaga's concert in New York."
To ask a question, input: "What are the details of the upcoming concerts?"
"""

import os
import chromadb
from langchain_ollama import OllamaEmbeddings, OllamaLLM

from rag import ChromaDBEmbeddingFunction

llm_model = 'qwen:1.8b'


def add_docs_to_collection(documents: list, ids: list):
    """
    Adds specified documents to the ChromaDB collection with associated IDs.

    Args:
        documents (list): A list of documents to be added to the collection.
        ids (list): A list of unique identifiers corresponding to each document.

    Returns:
        None
    """

    collection.add(
        documents=documents,
        ids=ids
    )


def query_chromadb(query_text: str, n_results: int = 1) -> tuple[list, list]:
    """
    Queries the ChromaDB collection for documents related to the provided query text.

    Args:
        query_text (str): The text to query against the document collection.
        n_results (int, optional): The number of results to return. Defaults to 1.

    Returns:
        tuple: A tuple containing two elements:
            - list: A list of retrieved documents.
            - list: A list of metadata associated with the retrieved documents.
    """

    results = collection.query(
        query_texts=[query_text],
        n_results=n_results
    )

    return results['documents'], results['metadatas']


def query_ollama(prompt: str, llm_model: str = llm_model) -> str:
    """
    Invokes the Ollama language model with a given prompt and returns the generated response.

    Args:
        prompt (str): The prompt to send to the Ollama model.
        llm_model (str, optional): The model to use for the query. Defaults to the global llm_model variable.

    Returns:
        str: The response generated by the Ollama model.
    """
    llm = OllamaLLM(model=llm_model)

    return llm.invoke(prompt)


def rag_pipeline(query_text: str) -> str:
    """
    Executes the Retrieval-Augmented Generation (RAG) pipeline by retrieving relevant documents
    and generating an answer using the Ollama model.

    Args:
        query_text (str): The query text for which to retrieve documents and generate an answer.

    Returns:
        str: The answer generated by the Ollama model based on the retrieved context.
    """

    retrieved_docs, metadata = query_chromadb(query_text)
    context = ' '.join(retrieved_docs[0]) if retrieved_docs else 'No relevant documents found.'
    prompt = 'Context: {}\n\nQuestion: {}\nAnswer:'.format(context, query_text)

    return query_ollama(prompt, llm_model)


def classify_user_intent(user_input: str) -> str:
    """
    Analyzes user input to determine if it is an intent to add a document or ask a question.

    Args:
        user_input (str): The input message from the user.

    Returns:
        str: A label indicating the user's intent, either 'ADD_DOCUMENT' or 'ASK_QUESTION'.
    """

    prompt = ('The user has sent this message:\n\n\"{}\"\n\nDecide whether this message is trying to ADD A DOCUMENT to '
              'the concert tour database or ASK A QUESTION.\n\nRespond with exactly one of the following labels:\n'
              '- ADD_DOCUMENT\n- ASK_QUESTION'.format(user_input))

    return query_ollama(prompt).strip()


def is_concert_related(document_text: str) -> bool:
    """
    Checks if the provided text is related to concerts, tours, or performers.

    Args:
        document_text (str): The text to analyze for concert-related content.

    Returns:
        bool: True if the text is related to concerts, otherwise False.
    """

    prompt = ('Determine whether the following text is related to a concert tour:\n\n{}\n\nRespond with YES if it is '
              'about concerts, tours, venues, or performers. Otherwise, respond with NO.'.format(document_text))

    return 'yes' in query_ollama(prompt).lower()


if __name__ == '__main__':
    """
    Main execution block for initializing the ChromaDB client, creating or retrieving a document 
    collection, and populating it with predefined concert-related documents. This block also 
    enters a loop to accept user queries, classify intents, and respond accordingly, allowing 
    users to add new documents or ask questions about existing ones.

    Usage:
    - Start the script to initialize the database and load starting documents.
    - Enter user queries to either add documents or ask questions.
    - Use 'exit' to terminate the program.
    """
    chroma_client = chromadb.PersistentClient(path=os.path.join(os.getcwd(), 'chroma_db'))

    embedding = ChromaDBEmbeddingFunction(
        OllamaEmbeddings(
            model=llm_model,
            base_url='http://localhost:11434'
        )
    )

    collection_name = 'collection_1'
    collection = chroma_client.get_or_create_collection(
        name=collection_name,
        metadata={'description': 'demo1'},
        embedding_function=embedding
    )

    starting_documents = [
        'Lady Gaga has announced her Chromatica II Tour for 2025, starting in September. Key venues include Madison '
        'Square Garden (New York) on September 18, and the United Center (Chicago) on September 23. She will be joined '
        'by Rina Sawayama as a special guest for select North American dates.',
        'Beyoncé\'s Renaissance World Tour will cover 15 cities across Europe in Spring 2026. Logistics teams are '
        'coordinating with local crews for stage setup, especially in Paris and Berlin, where venue capacities exceed '
        '70,000. Custom light rigs and portable dance floors are being shipped from LA.',
        'The O2 Arena will host multiple events during Winter 2025. It has a seating capacity of 20,000 and recently '
        'upgraded its sound system. Coldplay and Dua Lipa are scheduled for back-to-back concerts in December.',
        'Coldplay\’s 2026 World Tour will feature rotating guest appearances. Notable names include Sigrid, Mitski, and '
        'Stromae, depending on the continent. The band will play five nights at Foro Sol in Mexico City in March.',
        'An addendum to the Eras Tour 2025 includes three new dates in Australia: Sydney (Feb 3), Brisbane (Feb 6), '
        'and Melbourne (Feb 10). These are in addition to the previously announced Asia-Pacific leg. Venues confirmed '
        'include Accor Stadium and Marvel Stadium.',
        'The Southeast Asia leg of The Weeknd\'s tour in early 2026 includes shows in Bangkok, Kuala Lumpur, and Manila.'
        ' Due to customs delays, the logistics team is advised to pre-clear lighting equipment two weeks in advance and'
        ' confirm stage dimensions with each venue manager.',
        'Metallica’s "WorldWired II" Fall Tour 2025 includes stops in Detroit, Seattle, and Phoenix. The tour emphasizes'
        ' minimal setup time — under 6 hours per venue. All dates use a rotating stage layout, and tuning sessions are '
        'scheduled two hours before doors open.',
        'Billie Eilish will headline major European festivals in July 2025, including Roskilde (Denmark), Mad Cool '
        '(Spain), and Open’er (Poland). Her team requested environmentally friendly transport options for gear, and '
        'sustainable merch partnerships are underway.'
    ]
    doc_ids = ['doc' + str(x + 1) for x, _ in enumerate(starting_documents)]
    add_docs_to_collection(starting_documents, doc_ids)

    while True:
        try:
            user_input = input('(Use \'exit\' to exit.)\nEnter query: ')

            if user_input.lower() == 'exit':
                break

            intent = classify_user_intent(user_input)

            if intent == 'ADD_DOCUMENT':
                doc_text = user_input.split(':', 1)[-1].strip()

                if is_concert_related(doc_text):
                    doc_id = 'doc' + str(len(collection.get()['documents']) + 1)
                    add_docs_to_collection(doc_text, doc_id)

                    print('Document added with id {}.'.format(doc_id))
                    prompt = 'Give a short and concise description of this document:\n{}'.format(doc_text)
                    print(query_ollama(prompt))

                else:
                    print('Sorry, that document doesn\'t appear to be about concerts, gigs or tours ;(')
                    continue
            else:
                print('==========Response from LLM==========\n', rag_pipeline(user_input))
        except ValueError:
            print('Invalid input, please try again.')
            continue
